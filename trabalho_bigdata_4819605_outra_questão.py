from pyspark.sql import SparkSession
from pyspark.sql.functions import col, sum as spark_sum

# Identifica√ß√£o pessoal
print("RU_do_aluno:", "4819605")

# 1Ô∏è‚É£ Inicializa√ß√£o da sess√£o Spark
spark = SparkSession.builder.appName("trabalho_big_data_4819605_enunciado1").getOrCreate()

# 2Ô∏è‚É£ Leitura do CSV
df = spark.read.csv(
    "/app/imdb-reviews-pt-br.csv",
    header=True,
    quote='"',
    escape='"',
    multiLine=True,
    encoding='UTF-8'
)

print("‚úÖ Arquivo CSV carregado com sucesso.")

# 3Ô∏è‚É£ Filtrar apenas avalia√ß√µes negativas
negativos_df = df.filter(col('sentiment') == 'neg')

# 4Ô∏è‚É£ Somar os IDs dos filmes negativos
# Assumindo que a coluna 'id' √© num√©rica. Se estiver como string, converta com cast('int')
soma_ids = negativos_df.select(spark_sum(col('id').cast('int'))).collect()[0][0]

print("üîπ Soma de todos os IDs dos filmes negativos:", soma_ids)
